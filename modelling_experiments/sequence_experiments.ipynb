{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sequence_experiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BblKb6w1iMja"
      },
      "source": [
        "A first attempt at classifying sequences. Arguably, since we're normalising away the duration of sequences to all having 128 samples, this may actually now be better characterised by a simpler CNN? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edTO-yhMqh6y"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYqHvIYQX03n",
        "outputId": "fa39e3b8-24c5-4bcf-bd41-d0a850124b4e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx11SX4qYaPr",
        "outputId": "1598a763-20b0-4831-a67f-996d95cd72f7"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aligLwv5YtCX",
        "outputId": "2644bac3-97fb-4491-e951-b40b43260b82"
      },
      "source": [
        "!ls drive/MyDrive/Colab\\ Notebooks/sequence_data/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d1p01M\td1p10F\td1p19F\td1p28F\td1p37M\td1p46M\td1p55F\td2p04F\td2p13F\td2p22M\n",
            "d1p02M\td1p11F\td1p20F\td1p29F\td1p38M\td1p47M\td1p56F\td2p05F\td2p14F\td2p23F\n",
            "d1p03M\td1p12F\td1p21F\td1p30F\td1p39M\td1p48M\td1p57F\td2p06F\td2p15F\td2p24F\n",
            "d1p04M\td1p13F\td1p22F\td1p31F\td1p40M\td1p49F\td1p58F\td2p07F\td2p16F\td2p25F\n",
            "d1p05M\td1p14F\td1p23F\td1p32F\td1p41M\td1p50F\td1p59F\td2p08F\td2p17F\td2p26F\n",
            "d1p06M\td1p15F\td1p24F\td1p33F\td1p42M\td1p51F\td1p60F\td2p09F\td2p18M\td2p27F\n",
            "d1p07M\td1p16F\td1p25F\td1p34F\td1p43M\td1p52F\td2p01F\td2p10F\td2p19M\n",
            "d1p08F\td1p17F\td1p26F\td1p35F\td1p44M\td1p53F\td2p02F\td2p11F\td2p20M\n",
            "d1p09F\td1p18F\td1p27F\td1p36M\td1p45M\td1p54F\td2p03F\td2p12F\td2p21M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN71dDl5YyWA",
        "outputId": "ae744b6d-1b3a-4ef1-b025-8485a06796d5"
      },
      "source": [
        "%run drive/MyDrive/Colab\\ Notebooks/scripts/lstm_dataprep.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['participant', 'activity', 'activity_label', 'activity_sequence',\n",
            "       't_norm', 'front', 'lateral', 'vertical', 'rssi', 'phase', 'frequency'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "nQbirMRXiYva",
        "outputId": "fba49373-4752-4fc1-c92b-ce5a282b50e6"
      },
      "source": [
        "norm_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant</th>\n",
              "      <th>activity</th>\n",
              "      <th>activity_label</th>\n",
              "      <th>activity_sequence</th>\n",
              "      <th>t_norm</th>\n",
              "      <th>front</th>\n",
              "      <th>lateral</th>\n",
              "      <th>vertical</th>\n",
              "      <th>rssi</th>\n",
              "      <th>phase</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d1p01M</td>\n",
              "      <td>1</td>\n",
              "      <td>bed</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.272030</td>\n",
              "      <td>-0.082102</td>\n",
              "      <td>1.00820</td>\n",
              "      <td>-63.500000</td>\n",
              "      <td>2.425200</td>\n",
              "      <td>924.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d1p01M</td>\n",
              "      <td>1</td>\n",
              "      <td>bed</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007874</td>\n",
              "      <td>0.272030</td>\n",
              "      <td>-0.082102</td>\n",
              "      <td>1.00820</td>\n",
              "      <td>-63.287402</td>\n",
              "      <td>3.408128</td>\n",
              "      <td>923.187008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d1p01M</td>\n",
              "      <td>1</td>\n",
              "      <td>bed</td>\n",
              "      <td>1</td>\n",
              "      <td>0.015748</td>\n",
              "      <td>0.272030</td>\n",
              "      <td>-0.082102</td>\n",
              "      <td>1.00820</td>\n",
              "      <td>-63.074803</td>\n",
              "      <td>4.391055</td>\n",
              "      <td>922.124016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d1p01M</td>\n",
              "      <td>1</td>\n",
              "      <td>bed</td>\n",
              "      <td>1</td>\n",
              "      <td>0.023622</td>\n",
              "      <td>0.320501</td>\n",
              "      <td>-0.063247</td>\n",
              "      <td>0.98289</td>\n",
              "      <td>-63.137795</td>\n",
              "      <td>4.266798</td>\n",
              "      <td>922.301181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d1p01M</td>\n",
              "      <td>1</td>\n",
              "      <td>bed</td>\n",
              "      <td>1</td>\n",
              "      <td>0.031496</td>\n",
              "      <td>0.395284</td>\n",
              "      <td>-0.034156</td>\n",
              "      <td>0.94384</td>\n",
              "      <td>-63.350394</td>\n",
              "      <td>3.541497</td>\n",
              "      <td>923.151575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  participant  activity activity_label  ...       rssi     phase   frequency\n",
              "0      d1p01M         1            bed  ... -63.500000  2.425200  924.250000\n",
              "1      d1p01M         1            bed  ... -63.287402  3.408128  923.187008\n",
              "2      d1p01M         1            bed  ... -63.074803  4.391055  922.124016\n",
              "3      d1p01M         1            bed  ... -63.137795  4.266798  922.301181\n",
              "4      d1p01M         1            bed  ... -63.350394  3.541497  923.151575\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjls-mimq4YP"
      },
      "source": [
        ""
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f-BiSVAQ76a"
      },
      "source": [
        "##let's see if we can overfit on a mini dataset\n",
        "\n",
        "prepare mini train & test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ6pOJMCRB1O"
      },
      "source": [
        "Y = []\n",
        "X = []\n",
        "\n",
        "for name, group in norm_df.groupby(['participant', 'activity_sequence']):\n",
        "  Y.append(group['activity'].unique())\n",
        "  X.append(group[['front', 'lateral', 'vertical', 'rssi', 'phase', 'frequency']].to_numpy())"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTQMOrUyXyyg"
      },
      "source": [
        "mini_X = X[:12]\n",
        "mini_Y = Y[:12]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTpNx71Ec9oN",
        "outputId": "63c55aeb-df87-42a8-a042-2d7d883556f1"
      },
      "source": [
        "mini_Y"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([1]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([1]),\n",
              " array([3])]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeQ0tkJziPhk"
      },
      "source": [
        "# x = torch.tensor(x,dtype=torch.float32)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lJFR2Qzj-ZN"
      },
      "source": [
        "make mini train & test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKmdMyRvkmPk"
      },
      "source": [
        "y_test = mini_Y[4:8]\n",
        "del mini_Y[4:8]\n",
        "y_train = mini_Y"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fuDWtnrlPvo"
      },
      "source": [
        "x_test = mini_X[4:8]\n",
        "del mini_X[4:8]\n",
        "x_train = mini_X"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvwec5APDd_k",
        "outputId": "b28444b0-998c-4285-e906-38b74e5faf1f"
      },
      "source": [
        "# te.transpose(0, 2, 1).shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 6, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iZO8q2DlRMn"
      },
      "source": [
        "x_test = torch.tensor(np.array(x_test).transpose(0, 2, 1),dtype=torch.float64)\n",
        "x_train = torch.tensor(np.array(x_train).transpose(0, 2, 1),dtype=torch.float64)\n",
        "y_test = torch.tensor(np.array(y_test),dtype=torch.float64)\n",
        "y_train = torch.tensor(np.array(y_train),dtype=torch.float64)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXFibrCvoiHt"
      },
      "source": [
        "# adjust for the fact that one-hot encode assumes 0-indexing for classes\n",
        "\n",
        "y_test = y_test -1\n",
        "y_train = y_train -1"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KLYgeuZ_qOm",
        "outputId": "04db3c66-dbde-4f91-edc7-bbaeba50bb0d"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [3.],\n",
              "        [0.],\n",
              "        [2.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPPPsGMjQAmj"
      },
      "source": [
        "# one-hot encode y test & train\n",
        "y_test = torch.nn.functional.one_hot(y_test.to(torch.int64))\n",
        "y_train = torch.nn.functional.one_hot(y_train.to(torch.int64))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPPniXsjRWsP",
        "outputId": "cb736ac4-5a55-42b7-ea1b-76c6b098951e"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 1, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0, 1]],\n",
              "\n",
              "        [[1, 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 1, 0]]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDfXPK9Qiv-C"
      },
      "source": [
        "create train & test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nBifEP18Q1g"
      },
      "source": [
        "train_data = TensorDataset(x_train, y_train)\n",
        "test_data = TensorDataset(x_test, y_test)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fXV-5ROsVuW"
      },
      "source": [
        "Define static variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXK6qOsYoNCj"
      },
      "source": [
        "batch_size = 2   # since data is mini!\n",
        "input_size = 128  # length of sequence\n",
        "hidden_size = 32 # number of hidden neurons - should ensure we overfit\n",
        "layer_size = 2   # number of layers\n",
        "output_size = 10 # number of classes "
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSvuVMFKYNRO"
      },
      "source": [
        "training and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0KPxEh6YKxd"
      },
      "source": [
        "def get_accuracy(out, actual_labels, batchSize):\n",
        "    '''Saves the Accuracy of the batch.\n",
        "    Takes in the log probabilities, actual label and the batchSize (to average the score).'''\n",
        "    predictions = out.max(dim=1)[1]\n",
        "    # ajust for the fact one-hot encoding starts at 0\n",
        "    correct = (predictions == actual_labels).sum().item() + 1\n",
        "    accuracy = correct/batch_size\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUnD2FJ_YSXG"
      },
      "source": [
        "def train_network(model, train_data, test_data, batchSize=64, num_epochs=1, learning_rate=0.001):\n",
        "    \n",
        "    '''Trains the model and computes the average accuracy for train and test data.'''\n",
        "    \n",
        "    print('Get data ready...')\n",
        "    # Create dataloader for training dataset - so we can train on multiple batches\n",
        "    # Shuffle after every epoch\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batchSize, shuffle=True, drop_last=True)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batchSize, shuffle=True, drop_last=True)\n",
        "    \n",
        "    # Create criterion and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    \n",
        "    print('Training started...')\n",
        "    # Train the data multiple times\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Save Train and Test Loss\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        \n",
        "        # Set model in training mode:\n",
        "        model.train()\n",
        "        \n",
        "        for k, (seq, labels) in enumerate(train_loader):\n",
        "            \n",
        "            # Create log probabilities\n",
        "            out = model(seq)\n",
        "            # Clears the gradients from previous iteration\n",
        "            optimizer.zero_grad()\n",
        "            # Computes loss: how far is the prediction from the actual?\n",
        "            loss = criterion(out, labels)\n",
        "            # Computes gradients for neurons\n",
        "            loss.backward()\n",
        "            # Updates the weights\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Save Loss & Accuracy after each iteration\n",
        "            train_loss += loss.item()\n",
        "            train_acc += get_accuracy(out, labels, batchSize)\n",
        "            \n",
        "        \n",
        "        # Print Average Train Loss & Accuracy after each epoch\n",
        "        print('TRAIN | Epoch: {}/{} | Loss: {:.2f} | Accuracy: {:.2f}'.format(epoch+1, num_epochs, train_loss/k, train_acc/k))\n",
        "            \n",
        "            \n",
        "    print('Testing Started...')\n",
        "    # Save Test Accuracy\n",
        "    test_acc = 0\n",
        "    # Evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    for k, (seq, labels) in enumerate(test_loader):\n",
        "        \n",
        "        # Create logit predictions\n",
        "        out = model(images)\n",
        "        # Add Accuracy of this batch\n",
        "        test_acc += get_accuracy(out, labels, batchSize)\n",
        "        \n",
        "    # Print Final Test Accuracy\n",
        "    print('TEST | Average Accuracy per {} Loaders: {:.5f}'.format(k, test_acc/k) )"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6L3_KJZitC0"
      },
      "source": [
        "Adapted from a tutorial on image classification - doesn't work yet. I suspect un-stacking the 6 features into a single vector may work. Still need to work through the dimensions to ensure they're correct. To be continued! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJkIoS7bT-T-"
      },
      "source": [
        "\n",
        "\n",
        "class LSTM_SEQ(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, layer_size, output_size, bidirectional=True):\n",
        "        super(LSTM_SEQ, self).__init__()\n",
        "        \n",
        "        self.input_size, self.hidden_size, self.layer_size, self.output_size = input_size, hidden_size, layer_size, output_size\n",
        "        self.bidirectional = bidirectional\n",
        "        \n",
        "        # Step1: the LSTM model\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, layer_size, batch_first=True, bidirectional=bidirectional)\n",
        "        \n",
        "        # Step2: the FNN\n",
        "        if bidirectional: # we'll have 2 more layers\n",
        "            self.layer = nn.Linear(hidden_size*2, output_size)\n",
        "        else:\n",
        "            self.layer = nn.Linear(hidden_size, output_size)\n",
        "            \n",
        "            \n",
        "    def forward(self, sequences, prints=True):\n",
        "        if prints: print('sequences shape:', sequences.shape)\n",
        "        \n",
        "        # Set initial states\n",
        "        if self.bidirectional:\n",
        "            # Hidden state:\n",
        "            hidden_state = torch.zeros(self.layer_size*2, sequences.size(0), self.hidden_size)\n",
        "            # Cell state:\n",
        "            cell_state = torch.zeros(self.layer_size*2, sequences.size(0), self.hidden_size)\n",
        "        else:\n",
        "            # Hidden state:\n",
        "            hidden_state = torch.zeros(self.layer_size, sequences.size(0), self.hidden_size)\n",
        "            # Cell state:\n",
        "            cell_state = torch.zeros(self.layer_size, sequences.size(0), self.hidden_size)\n",
        "        if prints: print('hidden_state t0 shape:', hidden_state.shape, '\\n' +\n",
        "                         'cell_state t0 shape:', cell_state.shape)\n",
        "        \n",
        "        # LSTM:\n",
        "        output, (last_hidden_state, last_cell_state) = self.lstm(sequences, (hidden_state, cell_state))\n",
        "        if prints: print('LSTM: output shape:', output.shape, '\\n' +\n",
        "                         'LSTM: last_hidden_state shape:', last_hidden_state.shape, '\\n' +\n",
        "                         'LSTM: last_cell_state shape:', last_cell_state.shape)\n",
        "        # Reshape\n",
        "        output = output[:, -1, :]\n",
        "        if prints: print('output reshape:', output.shape)\n",
        "        \n",
        "        # FNN:\n",
        "        output = self.layer(output)\n",
        "        if prints: print('FNN: Final output shape:', output.shape)\n",
        "        \n",
        "        return output\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0nT0Ot0VLr-",
        "outputId": "afd38896-a05a-4aa6-8046-71b2f7f68ee2"
      },
      "source": [
        "lstm_example = LSTM_SEQ(input_size, hidden_size, layer_size, output_size)\n",
        "print('lstm_example:', lstm_example, '\\n')\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lstm_example: LSTM_SEQ(\n",
            "  (lstm): LSTM(128, 32, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (layer): Linear(in_features=64, out_features=10, bias=True)\n",
            ") \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "OYj3rmH-VYVn",
        "outputId": "d1ce51d2-191d-49c5-aa24-0173cbbbaa79"
      },
      "source": [
        "\n",
        "# Instantiate the model\n",
        "lstm_rnn = LSTM_SEQ(input_size, hidden_size, layer_size, output_size)\n",
        "\n",
        "# ==== TRAIN ====\n",
        "train_network(lstm_rnn, train_data, test_data, batchSize=2, num_epochs=10)\n",
        "\n",
        "#train_network(model, train_data, test_data, batchSize=64, num_epochs=1, learning_rate=0.001):\n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get data ready...\n",
            "Training started...\n",
            "sequences shape: torch.Size([2, 6, 128])\n",
            "hidden_state t0 shape: torch.Size([4, 2, 32]) \n",
            "cell_state t0 shape: torch.Size([4, 2, 32])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-549dd68ff3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ==== TRAIN ====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#train_network(model, train_data, test_data, batchSize=64, num_epochs=1, learning_rate=0.001):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-50e9d0c197d0>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(model, train_data, test_data, batchSize, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Create log probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Clears the gradients from previous iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-79340036b3da>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sequences, prints)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# LSTM:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_cell_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         if prints: print('LSTM: output shape:', output.shape, '\\n' +\n\u001b[1;32m     40\u001b[0m                          \u001b[0;34m'LSTM: last_hidden_state shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 692\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z_R-MnNXrMz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}